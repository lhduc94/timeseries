# ARIMA
## Autoregressive Model
Mô hình tự hồi quy là mô hình ước lượng giá trị tương lai của timeseries dựa vào các giá trị trong quá khứ cửa chính timeseries đó.

Công thức tự hồi quy được biểu diễn như sau

$$
y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \phi_3 y_{t-3} + .... + \phi_p y_{t-p} + \epsilon_t
$$

Hoặc có thể viết lại

$$
y_t = c + \sum^{p}_{1}\phi y_{t-i} + \epsilon_t
$$

Trong đó: $\epsilon_t$ là nhiễu trắng. Có thể nói mô hình này là mô hình hồi quy đa biến với các biến là các giá trị lag tại thời điểm từ $1$ đến $p$. Chúng ta kí hiệu mô hình này là $AR(p)$

Để sử dụng AR model, ta dùng class `AutoReg` của thư viện `statsmodels`, chúng ta dùng `root_mean_squared_error` để đánh giá mô hình. Mô hình sẽ được huấn luyện và dự đoán cho 7 ngày tiếp theo

```python
from statsmodels.tsa.ar_model import AutoReg
import pandas as pd 
import numpy as np

# Đọc dữ liệu
df = pd.read_csv('../data/daily-total-female-births.csv')
df.head()

# Chia dữ liệu thành train test
Y = df.Births.values
train, test = Y[:len(Y)-7], Y[len(Y)-7:]

# Huấn luyện mô hình với p=2
AR_model = AutoReg(train, lags=2)
AR_results = AR_model.fit()
# Dự đoán kết quả mô hình
Y_hat = AR_results.forecast(7)
for y_hat, y_true in zip(Y_hat, test):
    print(f'Predicted={y_hat} \tExpected={y_true}')
```

```python
Predicted=41.009982996211406 	Expected=44
Predicted=41.3395707860348 	    Expected=34
Predicted=41.741049087971845 	Expected=37
Predicted=41.8524930508191 	    Expected=52
Predicted=41.91850636281712 	Expected=48
Predicted=41.94330911921793 	Expected=55
Predicted=41.95535989900887 	Expected=50
```

Để xem các params của mô hình ta gọi `model_fit.params`. Trong đó giá trị đầu tiên là hằng số $c$, các giá trị tiếp theo tương ứng là các $\phi$ tại các lag 

```python
AR_results.params
```

```
array([29.46548462,  0.18468755,  0.11315929])
```

Để đánh giá kết quả mô hình, chúng ta dùng thư viện `sklearn.metrics`

```python
from sklearn.metrics import mean_squared_error
print('RMSE:', np.sqrt(mean_squared_error(test, Y_hat)))
```

```
8.110283777968577
```

Dưới đây là biểu đồ thể hiện giá trị Dự đoán và giá trị thực tế trong 7 ngày

![](../images/03/autoregressive.png)

Chúng ta có thể mô phỏng lại cách tính các giá trị dự đoán dựa trên các params của model với $c=29.46548462, \phi_1=0.18468755, \phi_2=0.11315929$

```python
Y_hat_sim = list(train[-2:])
c = 29.46548462
phi_1 = 0.18468755
phi_2 = 0.11315929

for i in range(7):
    predict = c + phi_1*Y_hat_sim[-1] + phi_2*Y_hat_sim[-2]
    Y_hat_sim.append(predict)

for a, b in zip(Y_hat_sim[2:], Y_hat):
    print(f"Simulated={a} \t Predicted={b}")
```

```
Simulated=41.00998312 	         Predicted=41.009982996211406
Simulated=41.33957094797416 	 Predicted=41.3395707860348
Simulated=41.74104926920371 	 Predicted=41.741049087971845
Simulated=41.85249324133591 	 Predicted=41.8524930508191
Simulated=41.918506557292 	     Predicted=41.91850636281712
Simulated=41.94330931564456 	 Predicted=41.94330911921793
Simulated=41.95536009628208 	 Predicted=41.95535989900887
```


## Moving Average Model

Thay vì sử dụng các giá trị trong quá khứ làm đầu vào để dự đoán, Moving Average Model sử dụng các lỗi dự báo của quá khứ để dự đoán giá trị tiếp theo. 

Lưu ý cần phân biệt Moving Average Smoothing và Moving Average Model.

**Moving Average Smoothing**

> Ý tưởng chính là sử dụng một cửa sổ trượt trên chuỗi dữ liệu và tính trung bình của các giá trị trong cửa sổ đó. Kết quả là chuỗi dữ liệu mới, nơi mà các dao động ngắn hạn hoặc nhiễu được giảm thiểu, giúp nhận diện xu hướng và mô hình hóa chuỗi dữ liệu dễ dàng hơn.

> Ví dụ, khi bạn thấy một chuỗi dữ liệu có nhiều dao động ngắn hạn và bạn muốn làm trơn nó để nhận diện xu hướng chung, bạn có thể sử dụng moving average smoothing để tạo ra một phiên bản làm trơn của chuỗi dữ liệu.

Công thức MA model như sau

$$
y_t = c + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \theta_3 \epsilon_{t-3} + .... + \theta_q \epsilon_{t-q} + \epsilon_t 
$$
Hoặc có thể viết lại

$$
y_t = c  + \sum^{q}_{i=1}\theta_{i}\epsilon_{t-i} +  \epsilon_t
$$

Trong đó $c$ là trung bình series, $\epsilon_{t-i}$ là white noise tại $t-i$. Trong thực tế, chúng ta không có quan sát cho các giá trị white noise này, do đó nó không thực sự là hồi quy theo nghĩa hiểu thông thường.

Trong thư viện `statsmodels` không hỗ trợ chính thức cách tính **Moving Average Model**, nhưng chúng ta có thể áp dụng thông qua `ARIMA`. 

Ví dụ về cách sử dụng ARMA

```python
# Huấn luyện mô hình với q=2
MA_model = ARIMA(train, order=(0, 0, 2))
MA_results = MA_model.fit()
# Dự đoán kết quả mô hình
Y_hat = MA_results.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)
for y_hat, y_true in zip(Y_hat, test):
    print(f'Predicted={y_hat} \tExpected={y_true}')
```

```
Predicted=41.11548396873163 	Expected=44
Predicted=41.5656013608698  	Expected=34
Predicted=41.89874024020355 	Expected=37
Predicted=41.89874024020355 	Expected=52
Predicted=41.89874024020355 	Expected=48
Predicted=41.89874024020355 	Expected=55
Predicted=41.89874024020355 	Expected=50
```

xem các tham số $\theta$

```python
MA_results.maparams
```

```
array([0.17900771,  0.11330768])
```

xem tham số $c$

```python
MA_results.params[0]
```

```
41.89874024020355
```
Đánh giá kết quả mô hình

```
print('RMSE:', np.sqrt(mean_squared_error(test, Y_hat)))
```

```
RMSE: 8.15992514853609
```

để xem các espilon

```python
MA_results.resid
```

```
array([-6.89874024e+00, -8.58294190e+00, -9.63603195e+00, -8.20730676e+00,
        4.66081766e+00, -1.28031243e+01,  4.86502357e+00,  1.68107497e+00,
       -4.75091009e+00, -1.42387694e+01, -8.11576067e-01, -7.14009987e+00,
        1.44713505e+01,  3.31980458e+00,  8.67273907e-01, -5.43014833e+00,
        8.97502940e+00,  1.09937808e-01, -1.93535976e+00,  1.04352473e+01,
       -9.54743886e+00,  1.16279312e+01, -3.89843143e+00, -1.05184249e+01,
       -2.57413881e+00,  2.75386884e+00, -3.10003429e+00, -6.65584469e+00,
        3.64396501e+00, -3.79687973e+00, -1.76319587e+01, -1.53122680e+01,
       -6.15988974e+00,  4.93892517e+00, -4.08488310e+00,  8.27286716e+00,
       -4.91679863e+00,  9.04402521e+00, -1.19605794e+01, -9.78246182e+00,
        1.22076214e+01, -6.97557054e+00,  2.96672336e+00,  9.36057914e+00,
       -9.91050866e+00,  1.08146917e+01,  4.28828332e+00,  1.10823629e+00,
        3.41698146e+00, -3.63597797e+00,  6.36495760e+00, -5.62613250e+00,
       -6.61281774e+00,  1.19224892e+01, -1.28367470e+00,  1.98013778e+00,
       -3.10774997e+00, -4.56679385e+00, -1.07291170e+01, -4.46069271e+00,
       -1.18845504e+01,  5.73411672e+00, -7.57858046e+00, -5.19183537e+00,
        9.88934975e+00,  9.19264723e-01, -4.18383504e+00, -9.25396125e+00,
       -7.68149134e-01,  4.28730931e+00,  4.20835525e-01, -3.45985814e+00,
       -1.03270828e+01, -1.26580842e+01, -8.46270768e+00,  3.05040793e+00,
        4.51410303e+00, -2.05243416e+00, -6.04282126e+00,  4.41552794e+00,
        3.99554429e+00, -1.14286735e-01, -4.33100791e+00, -7.11050685e+00,
       -5.13516819e+00,  1.58261695e+01, -8.14989264e+00, -1.02330732e+01,
        1.08565043e+01, -1.68265240e+00, -3.82765785e+00, -2.29025133e-02,
        5.53906254e+00, -8.88768013e+00, -4.93539530e+00, -7.00822395e+00,
       -5.08499588e+00, -2.19440112e+00, -2.92975640e+00, -7.12564874e+00,
...
       -3.63316822e+00,  8.57959651e+00, -2.28883118e-02,  1.33222726e-01,
       -7.91999471e+00, -1.49609526e+00, -5.73353138e+00,  1.12971252e+01,
        3.72864038e+00,  8.15375327e+00, -4.78080858e+00, -1.96682154e+00,
        9.95038338e-01,  1.45996217e-01,  1.09623798e+01, -4.87763328e+00,
       -2.26772814e+00, -2.94012608e+00])
```
Dưới đây là biểu đồ thể hiện giá trị Dự đoán và giá trị thực tế trong 7 ngày

![](../images/03/MA_model.png)

Nếu để ý kĩ, chúng ta sẽ thấy kể từ giá trị dự đoán thứ 3, giá trị dự đoán bằng đầu là một giá trị không đổi 41.89874024020355. Lý do là mô hình không biết trước các sai số dự đoán của các giá trị tiếp theo để từ bước tính toán thứ 3.
Để mô phỏng lại cách tính toán.
Ta có $c = 41.89874024 ,\theta_1 = 0.17900771, \theta_2 = 0.11330768$
và
$resid_t = -2.94012608, resid_{t-1}=-2.26772814$
```python
c = 41.89874024
theta_1 = 0.17900771
theta_2 = 0.11330768
resid_t = -2.94012608
resid_t_previous_1 = -2.2677281
```

lúc này, giá trị dự báo cho T+1 sẽ là:
```python
c + theta_1*resid_t + theta_2*resid_t_previous_1
```

```
41.11548399342612
```
lúc này, giá trị dự báo cho T+2 sẽ là:

```python
resid_t_previous_1 = resid_t
resid_t = 0
c + theta_1*resid_t + theta_2*resid_t_previous_1
```

```
41.565601374967706
```

Và giá trị từ T+3 trở đi sẽ là

```python
resid_t_previous_1 = resid_t #lúc này resid_t từ T+2 đã bằng 0 nên giá trị resid_t_previous_1 cũng bằng 0, do đó kết quả trở về giá trị trung bình c
resid_t = 0
c + theta_1*resid_t + theta_2*resid_t_previous_1
```

```
41.89874024
```

Đây cũng chính là điểm yếu của mô hình Moving Average


## AutoRegressive Moving Average Model

Như cái tên của nó, mô hình này kết hợp 2 Mô hình Autoregressive và Moving Average

Nhăc lại công thức AR

$$
y_t = c + \sum^{p}_{1}\phi y_{t-i} + \epsilon_t
$$

Và công thức MA

$$
y_t = c  + \sum^{q}_{i=1}\theta_{i}\epsilon_{t-i} +  \epsilon_t
$$

Do đó công thức ARMA là kết hợp cả hai công thức.

$$
y_t = c + \epsilon_t + \sum^{p}_{1}\phi y_{t-i}  + \sum^{q}_{i=1}\theta_{i}\epsilon_{t-i}
$$

Tương tự, trong thư viện `statsmodels` không hỗ trợ chính thức cách tính **Moving Average Model**, nhưng chúng ta có thể áp dụng thông qua `ARIMA`. Ở phần sau chúng ta sẽ tìm hiểu về `ARIMA` rồi quay ngược lại ví dụ về `MA`

### Autogregressive Integrated Moving Average Model